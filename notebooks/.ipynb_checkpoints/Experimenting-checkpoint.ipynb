{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c81f04dd",
   "metadata": {},
   "source": [
    "# Experimenting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5e47030",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from copy import deepcopy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "import tqdm\n",
    "import os\n",
    "import mlp.data_providers as data_providers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f90f5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearLayerWithActivation(nn.Module):\n",
    "    def __init__(self, input_shape, num_units, bias=False, activation_type=nn.ReLU()):\n",
    "        super(LinearLayerWithActivation, self).__init__()\n",
    "        self.activation_type = activation_type\n",
    "        self.weights = nn.Parameter(torch.empty(size=(num_units, input_shape[1]), requires_grad=True))\n",
    "        \n",
    "        nn.init.normal_(self.weights)\n",
    "        \n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.zeros(num_units), requires_grad=True)\n",
    "        else:\n",
    "            self.bias = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.linear(x, self.weights, self.bias)\n",
    "        out = self.activation_type.forward(out)\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcf713c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLayerFCCNetwork(nn.Module):\n",
    "    def __init__(self, input_shape, num_hidden_units, num_output_units, num_hidden_layers):\n",
    "        super(MultiLayerFCCNetwork, self).__init__()\n",
    "        self.input_shape = input_shape\n",
    "        self.num_hidden_units = num_hidden_units\n",
    "        self.num_output_units = num_output_units\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "        \n",
    "        x_dummy = torch.zeros(input_shape)\n",
    "        \n",
    "        self.layer_dict = nn.ModuleDict() # Allows us to initialize modules within a dictionary structure.\n",
    "        out = x_dummy\n",
    "        for i in range(self.num_hidden_layers):\n",
    "            self.layer_dict['layer_{}'.format(i)] = LinearLayerWithActivation(input_shape=out.shape, \n",
    "                                                             num_units=self.num_hidden_units, bias=True,\n",
    "                                                                       activation_type=nn.PReLU())\n",
    "            \n",
    "            out = self.layer_dict['layer_{}'.format(i)].forward(out)\n",
    "        \n",
    "        self.layer_dict['output_layer'] = LinearLayerWithActivation(input_shape=out.shape, \n",
    "                                                             num_units=self.num_output_units, \n",
    "                                                             bias=True, activation_type=nn.Identity())\n",
    "        out = self.layer_dict['output_layer'].forward(out)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        for i in range(self.num_hidden_layers):\n",
    "            out = self.layer_dict['layer_{}'.format(i)].forward(out)\n",
    "\n",
    "        out = self.layer_dict['output_layer'].forward(out)\n",
    "        return out\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25bda8a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer_0\n",
      "layer_1\n",
      "layer_2\n",
      "layer_3\n",
      "output_layer\n",
      "layer_dict.layer_0.weights\n",
      "layer_dict.layer_0.bias\n",
      "layer_dict.layer_0.activation_type.weight\n",
      "layer_dict.layer_1.weights\n",
      "layer_dict.layer_1.bias\n",
      "layer_dict.layer_1.activation_type.weight\n",
      "layer_dict.layer_2.weights\n",
      "layer_dict.layer_2.bias\n",
      "layer_dict.layer_2.activation_type.weight\n",
      "layer_dict.layer_3.weights\n",
      "layer_dict.layer_3.bias\n",
      "layer_dict.layer_3.activation_type.weight\n",
      "layer_dict.output_layer.weights\n",
      "layer_dict.output_layer.bias\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(16*128).view(16, 128).float()\n",
    "y = torch.arange((16))\n",
    "\n",
    "fcc_net = MultiLayerFCCNetwork(input_shape=x.shape, num_hidden_units=64, num_output_units=512, \n",
    "                               num_hidden_layers=4)\n",
    "for x in fcc_net.layer_dict:\n",
    "    print(x)\n",
    "    \n",
    "for x in fcc_net.named_parameters():\n",
    "    print(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02383337",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, value in fcc_net.named_parameters():\n",
    "            #print(name, value.shape)\n",
    "            if all(item in name for item in ['conv', 'weight']):\n",
    "                print(name)\n",
    "            if all(item in name for item in ['linear', 'weight']):\n",
    "                print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0915b160",
   "metadata": {},
   "source": [
    "### Learning to use pytorch_mlp_framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb41710",
   "metadata": {},
   "source": [
    "Running the following code gives the following output"
   ]
  },
  {
   "cell_type": "raw",
   "id": "87a362b5",
   "metadata": {},
   "source": [
    "python pytorch_mlp_framework/train_evaluate_image_classification_system.py --batch_size 100 --seed 0 --num_filters 32 --num_stages 1 --num_blocks_per_stage 0 --experiment_name VGG_02 --num_classes 100 --block_type 'conv_block' --weight_decay_coefficient 0.00000 --use_gpu True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f683c4",
   "metadata": {},
   "source": [
    "```System learnable parameters\n",
    "model.layer_dict.input_conv.layer_dict.conv_0.weight torch.Size([32, 3, 3, 3])\n",
    "model.layer_dict.input_conv.layer_dict.bn_0.weight torch.Size([32])\n",
    "model.layer_dict.input_conv.layer_dict.bn_0.bias torch.Size([32])\n",
    "model.layer_dict.reduction_block_0.layer_dict.conv_0.weight torch.Size([32, 32, 3, 3])\n",
    "model.layer_dict.reduction_block_0.layer_dict.conv_0.bias torch.Size([32])\n",
    "model.layer_dict.reduction_block_0.layer_dict.conv_1.weight torch.Size([32, 32, 3, 3])\n",
    "model.layer_dict.reduction_block_0.layer_dict.conv_1.bias torch.Size([32])\n",
    "model.logit_linear_layer.weight torch.Size([100, 32])\n",
    "model.logit_linear_layer.bias torch.Size([100])\n",
    "Total number of parameters 22724\n",
    "Total number of conv layers 4\n",
    "Total number of linear layers 1```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1e0a8f",
   "metadata": {},
   "source": [
    "And the \"layers\" are `input_conv` and `reduction_block_0`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703c923d",
   "metadata": {},
   "source": [
    "Finally, we have the following from the documentation:\n",
    "```\n",
    "Welcome to the MLP course's Pytorch training and inference helper script\n",
    "\n",
    "optional arguments:\n",
    "  -h, --help            show this help message and exit\n",
    "  --batch_size [BATCH_SIZE]\n",
    "                        Batch_size for experiment\n",
    "  --continue_from_epoch [CONTINUE_FROM_EPOCH]\n",
    "                        Which epoch to continue from. \n",
    "                        If -2, continues from where it left off\n",
    "                        If -1, starts from scratch\n",
    "                        if >=0, continues from given epoch\n",
    "  --seed [SEED]         Seed to use for random number generator for experiment\n",
    "  --image_num_channels [IMAGE_NUM_CHANNELS]\n",
    "                        The channel dimensionality of our image-data\n",
    "  --image_height [IMAGE_HEIGHT]\n",
    "                        Height of image data\n",
    "  --image_width [IMAGE_WIDTH]\n",
    "                        Width of image data\n",
    "  --num_stages [NUM_STAGES]\n",
    "                        Number of convolutional stages in the network. A stage\n",
    "                        is considered a sequence of convolutional layers where\n",
    "                        the input volume remains the same in the spacial\n",
    "                        dimension and is always terminated by a dimensionality\n",
    "                        reduction stage\n",
    "  --num_blocks_per_stage [NUM_BLOCKS_PER_STAGE]\n",
    "                        Number of convolutional blocks in each stage, not\n",
    "                        including the reduction stage. A convolutional block\n",
    "                        is made up of two convolutional layers activated using\n",
    "                        the leaky-relu non-linearity\n",
    "  --num_filters [NUM_FILTERS]\n",
    "                        Number of convolutional filters per convolutional\n",
    "                        layer in the network (excluding dimensionality\n",
    "                        reduction layers)\n",
    "  --num_epochs [NUM_EPOCHS]\n",
    "                        The experiment's epoch budget\n",
    "  --num_classes [NUM_CLASSES]\n",
    "                        The experiment's epoch budget\n",
    "  --experiment_name [EXPERIMENT_NAME]\n",
    "                        Experiment name - to be used for building the\n",
    "                        experiment folder\n",
    "  --use_gpu [USE_GPU]   A flag indicating whether we will use GPU acceleration\n",
    "                        or not\n",
    "  --weight_decay_coefficient [WEIGHT_DECAY_COEFFICIENT]\n",
    "                        Weight decay to use for Adam\n",
    "  --block_type BLOCK_TYPE\n",
    "                        Type of convolutional blocks to use in our network\n",
    "                        (This argument will be useful in running experiments\n",
    "                        to debug your network)\n",
    "                        \n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89262459",
   "metadata": {},
   "source": [
    "The parameters that seem to control the number of layers are `--num_stages`, `--num_blocks_per_stage` and (probably) `--num_filters`.\n",
    "\n",
    "Here, we've set num_stages to 1, num_blocks_per_stage to 0. Intuitively, this sounds like there should be 0 conv layers. Instead, we have 4 -- why?\n",
    "\n",
    "We've also set num_filters to 32, so that has something to do.\n",
    "\n",
    "I'm also not sure what's the difference between `--num_epochs` and `--num_classes`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d11dc18",
   "metadata": {},
   "source": [
    "`--num_classes` is actually the number of output classes, as expected\n",
    "\n",
    "filters = feature maps? so `num_filters` is actually number of feature maps\n",
    "   - but why does FCC also have that parameter? because here num_filters is apparently used as the number of hidden units.\n",
    "\n",
    "`--num_blocks_per_stage` is 0, so the only layers are:\n",
    "   - the input conv layer (what's `EntryConvolutionalBlock`?) which has 32 \"filters\"\n",
    "   - one reduction stage for one stage in `--num_stages`\n",
    "\n",
    "what's `EntryConvolutionalBlock`?\n",
    "   - it has conv parameters and bn parameters, what are they?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a8e740",
   "metadata": {},
   "source": [
    "when the ExperimentBuilder() says that there's 4 convolutional layers, it's talking about:\n",
    "- `model.layer_dict.input_conv.layer_dict.conv_0`\n",
    "- `model.layer_dict.input_conv.layer_dict.bn_0`\n",
    "- `model.layer_dict.reduction_block_0.layer_dict.conv_0`\n",
    "- `model.layer_dict.reduction_block_0.layer_dict.conv_1` \n",
    "i.e. 2 conv layers in `input_conv` and 2 conv layers in `reduction_block_0`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f868705f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1212,  0.0902,  0.9037],\n",
      "        [-1.5467, -0.3662, -0.8754],\n",
      "        [-0.3033,  0.9105, -0.7133]])\n",
      "tensor(-0.1977)\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(3, 3)\n",
    "print(a)\n",
    "t = torch.mean(a)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5924edbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = [1,2]\n",
    "b.append(float(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dad13b68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, -0.19769951701164246]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "040d1cc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9341001609961191"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(b)/len(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6839117",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_r = []\n",
    "for x in self.model.layer_dict:\n",
    "        for y in locals()[x].layer_dict:\n",
    "            layer_plotname = x + '_' + y\n",
    "            layer_realname = 'model.layer_dict.' + x + '.layer_dict.' + y\n",
    "\n",
    "            layers.append(layer_plotname)\n",
    "            layers_r.append(layer_realname)\n",
    "\n",
    "        for layer in globals()[layers_r]:\n",
    "            grads = []\n",
    "            for t in layer.named_parameters:\n",
    "                grads.append(float(torch.mean(t.grad)))\n",
    "            all_grads.append(sum(grads)/len(grads))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced84f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "    for x in self.named_parameters():\n",
    "            # now classify by layer, calculate the avg grads per layer and append name and avg grads to layers and all_grads\n",
    "            for block in self.model.layer_dict:\n",
    "                for layer in locals()[block].layer_dict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f7500aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layer_dict.input_conv.layer_dict.conv_0.weight\n",
      "['model', 'layer_dict', 'input_conv', 'layer_dict', 'conv_0', 'weight']\n",
      "input_conv_conv_0\n"
     ]
    }
   ],
   "source": [
    "rlayer = 'model.layer_dict.input_conv.layer_dict.conv_0.weight'\n",
    "print(rlayer)\n",
    "par = rlayer.split('.')\n",
    "print(par)\n",
    "layer = par[2]+'_'+par[4]\n",
    "print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e535a9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layer_dict.input_conv.layer_dict.conv_0.weight\n"
     ]
    }
   ],
   "source": [
    "if par[2] and par[4] in rlayer:\n",
    "    print(rlayer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8bc6d7ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a72c9da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes\n"
     ]
    }
   ],
   "source": [
    "name = 'logit_linear_layer.weight'\n",
    "if all(item in name for item in ['linear', 'weight']):\n",
    "    print('Yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c57893b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes\n"
     ]
    }
   ],
   "source": [
    "if 'weight' in name:\n",
    "    print('Yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d9b0b495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9973,  0.8574,  0.2572],\n",
       "        [-0.5075, -0.9552, -1.8104],\n",
       "        [-1.3216, -0.9684, -0.0414]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(3,3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e44b126f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.3509, -0.4538, -0.7192],\n",
       "        [-0.3950, -0.7167, -0.3476],\n",
       "        [ 0.0886,  1.3320, -0.1409]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.randn(3,3)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "875a4bf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.3482,  0.4036, -0.4620],\n",
       "        [-0.9026, -1.6719, -2.1581],\n",
       "        [-1.2330,  0.3635, -0.1822]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "bd0afbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(100, 32, 32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "33336377",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionalDimensionalityReductionBlockBNRC(nn.Module):\n",
    "    def __init__(self, input_shape, num_filters, kernel_size, padding, bias, dilation, reduction_factor):\n",
    "        super(ConvolutionalDimensionalityReductionBlockBNRC, self).__init__()\n",
    "\n",
    "        self.num_filters = num_filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.input_shape = input_shape\n",
    "        self.padding = padding\n",
    "        self.bias = bias\n",
    "        self.dilation = dilation\n",
    "        self.reduction_factor = reduction_factor\n",
    "        self.build_module()\n",
    "\n",
    "    def build_module(self):\n",
    "        self.layer_dict = nn.ModuleDict()\n",
    "        x = torch.zeros(self.input_shape)\n",
    "        out = x\n",
    "        self.layer_dict['conv_r'] = nn.Conv2d(in_channels=out.shape[1], out_channels=self.num_filters, bias=self.bias,\n",
    "                                              kernel_size=1, dilation=self.dilation, stride=2)\n",
    "        self.layer_dict['conv_0'] = nn.Conv2d(in_channels=out.shape[1], out_channels=self.num_filters, bias=self.bias,\n",
    "                                              kernel_size=self.kernel_size, dilation=self.dilation,\n",
    "                                              padding=self.padding, stride=1)\n",
    "\n",
    "        out = self.layer_dict['conv_0'].forward(out)\n",
    "        self.layer_dict['bn_0'] = nn.BatchNorm2d(num_features=out.shape[1])\n",
    "        out = F.leaky_relu(self.layer_dict['bn_0'].forward(out))\n",
    "        out = F.avg_pool2d(out, self.reduction_factor)\n",
    "        self.layer_dict['conv_1'] = nn.Conv2d(in_channels=out.shape[1], out_channels=self.num_filters, bias=self.bias,\n",
    "                                              kernel_size=self.kernel_size, dilation=self.dilation,\n",
    "                                              padding=self.padding, stride=1)\n",
    "\n",
    "        out = self.layer_dict['conv_1'].forward(out)\n",
    "        self.layer_dict['bn_1'] = nn.BatchNorm2d(num_features=out.shape[1])\n",
    "        \n",
    "        out = self.layer_dict['bn_1'].forward(out) + self.layer_dict['conv_r'].forward(x)\n",
    "        out = F.leaky_relu(out)\n",
    "\n",
    "        print(out.shape)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "\n",
    "        out = self.layer_dict['conv_0'].forward(out)\n",
    "        out = F.leaky_relu(self.layer_dict['bn_0'].forward(out))\n",
    "\n",
    "        out = F.avg_pool2d(out, self.reduction_factor)\n",
    "\n",
    "        out = self.layer_dict['conv_1'].forward(out)\n",
    "        out = self.layer_dict['bn_1'].forward(out) + self.layer_dict['conv_r'].forward(x)\n",
    "        out = F.leaky_relu(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4bfd972b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 32, 32, 32])\n",
      "torch.Size([100, 32, 16, 16])\n",
      "torch.Size([100, 32, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "reduction_block = ConvolutionalDimensionalityReductionBlockBNRC(input_shape=x.shape, num_filters=32, kernel_size=3, padding=1, bias=True, dilation=1, reduction_factor=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "107c6e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 32, 32, 16])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = x#.view(-1,x.shape[2])\n",
    "linear_proj = nn.Linear(in_features=a.shape[2], out_features=16)\n",
    "(linear_proj.forward(a)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8980b3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionalProcessingBlockBNRC(nn.Module):\n",
    "    def __init__(self, input_shape, num_filters, kernel_size, padding, bias, dilation):\n",
    "        super(ConvolutionalProcessingBlockBNRC, self).__init__()\n",
    "\n",
    "        self.num_filters = num_filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.input_shape = input_shape\n",
    "        self.padding = padding\n",
    "        self.bias = bias\n",
    "        self.dilation = dilation\n",
    "\n",
    "        self.build_module()\n",
    "\n",
    "    def build_module(self):\n",
    "        self.layer_dict = nn.ModuleDict()\n",
    "        x = torch.zeros(self.input_shape)\n",
    "        out = x\n",
    "\n",
    "        self.layer_dict['conv_0'] = nn.Conv2d(in_channels=out.shape[1], out_channels=self.num_filters, bias=self.bias,\n",
    "                                              kernel_size=self.kernel_size, dilation=self.dilation,\n",
    "                                              padding=self.padding, stride=1)\n",
    "\n",
    "\n",
    "\n",
    "        out = self.layer_dict['conv_0'].forward(out)\n",
    "        self.layer_dict['bn_0'] = nn.BatchNorm2d(num_features=out.shape[1])\n",
    "        out = F.leaky_relu(self.layer_dict['bn_0'].forward(out))\n",
    "\n",
    "        self.layer_dict['conv_1'] = nn.Conv2d(in_channels=out.shape[1], out_channels=self.num_filters, bias=self.bias,\n",
    "                                              kernel_size=self.kernel_size, dilation=self.dilation,\n",
    "                                              padding=self.padding, stride=1)\n",
    "\n",
    "\n",
    "\n",
    "        out = self.layer_dict['conv_1'].forward(out)\n",
    "        self.layer_dict['bn_1'] = nn.BatchNorm2d(num_features=out.shape[1])\n",
    "        out = self.layer_dict['bn_1'].forward(out) + x\n",
    "        out = F.leaky_relu(out)\n",
    "\n",
    "        print(out.shape, x.shape)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "\n",
    "        out = self.layer_dict['conv_0'].forward(out)\n",
    "        out = F.leaky_relu(self.layer_dict['bn_0'].forward(out))\n",
    "\n",
    "        out = self.layer_dict['conv_1'].forward(out)\n",
    "        out = self.layer_dict['bn_1'].forward(out) + x\n",
    "        out = F.leaky_relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5fedbae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 32, 32, 32]) torch.Size([100, 32, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "conv_block = ConvolutionalProcessingBlockBNRC(input_shape=x.shape, num_filters=32, kernel_size=3, padding=1, bias=False, dilation=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4e0b67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
